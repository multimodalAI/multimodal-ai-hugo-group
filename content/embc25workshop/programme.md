---
# An instance of the People widget.
# Documentation: https://wowchemy.com/docs/page-builder/
widget: blank

# This file represents a page section.
headless: true

# Order that this section appears on the page.
weight: 30

title: Programme
subtitle: 

content:
  # Choose which groups/teams of users to display.
  #   Edit `user_groups` in each user's profile to add them to one or more of these groups.
#  user_groups:
#    - Principal Investigators
#    - Researchers
#    - Grad Students
#    - Administration
#    - Visitors
#   - Alumni
design:
  show_interests: false
  show_role: true
  show_social: true
---

<center>

|  |
|:----------------|
| **Welcome and Opening**: _Towards Deployment-Centric Multimodal AI_ - Prof. Haiping Lu |
| **Introduction to the Tutorials** |
| **Hands-On Sessions** (run in parallel across four application areas):<br>• Brain Disorder Diagnosis (Imaging + Phenotypic Features)<br>• Cardiothoracic Abnormality Assessment (X-ray + ECG)<br>• Cancer Classification (Multi-omics)<br>• Drug–Target Interaction Prediction (Protein + Molecular) |
| **Open Sharing and Discussion** |
| **Closing** |

</center>

These hands-on tutorials will use public imaging, omics, and molecular datasets, including MIMIC ([Chest X-ray](https://physionet.org/content/mimic-cxr/2.1.0/) and [ECG](https://physionet.org/content/mimic-iv-ecg/1.0/)), [ABIDE](https://fcon_1000.projects.nitrc.org/indi/abide/abide_I.html), [TCGA](https://www.cancer.gov/ccg/research/genome-sequencing/tcga), [BindingDB](https://www.bindingdb.org/rwd/bind/index.jsp), and [BioSNAP](https://snap.stanford.edu/biodata/), and follow a standardised machine learning pipeline: data loading, preprocessing, embedding, prediction, evaluation, and interpretation, using the open-source multimodal AI library [PyKale](https://github.com/pykale/pykale).
